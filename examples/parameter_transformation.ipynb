{
 "cells": [
  {
   "cell_type": "code",
   "id": "e146d7baac252de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:04:30.653414Z",
     "start_time": "2024-10-05T15:04:30.648345Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from wimusim.dataset import CPM"
   ],
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will demonstrate how to apply **parameter transformations** in WIMUSim to introduce realistic variations in the generated virtual IMU data. This technique allows us to expand the diversity of IMU datasets without requiring additional real-world data collection. By systematically altering the identified WIMUSim parameters, we can simulate a broad range of conditions, including varying body morphologies, sensor placements, and hardware imperfections.\n",
    "\n",
    "### What We Will Do in This Notebook\n",
    "1. **Prepare the Identified Parameters**: We start by loading the optimized parameters for the REALDISP dataset (subjects 1 to 10) under the ideal scenario. \n",
    "   \n",
    "2. **Define the Comprehensive Parameter Mixing (CPM) Object**: Using the loaded parameters, we will define a `CPM` object, which allows us to generate new combinations of the Body (B), Dynamics (D), Placement (P), and Hardware (H) parameters to reflect different subject configurations.\n",
    "\n",
    "3. **Generate New Data**: We will use the defined `CPM` object to generate a diverse set of virtual IMU data by systematically varying the B, D, P, and H parameters. This section will include a demonstration of how to use the transformed data with PyTorch's `DataLoader` for training deep learning models.\n",
    "\n",
    "4. **Personalized Dataset Generation (PDG)**: We will apply a simple modification when defining a CPM object to create subject-specific datasets. This is useful for generating personalized data for specific subjects by fixing some parameters while allowing others to vary, simulating a more realistic variation for a particular individual.\n",
    "\n",
    "By the end of this notebook, you will understand how to use WIMUSim’s **CPM** and **PDG** modules to generate a wide range of synthetic IMU data."
   ],
   "id": "9a073461b9ddb54c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **1. Prepare the Identified Parameters**\n",
    "\n",
    "To begin, we need to load the optimized parameters identified for the **REALDISP** dataset. These parameters correspond to **subjects 1 to 10** under the **\"ideal scenario\"** and serve as the baseline configurations for generating new virtual IMU data in WIMUSim.\n",
    "\n",
    "### **Loading the Identified Parameters**\n",
    "Before proceeding, please download the optimized parameters from [this link](https://sussex.box.com/s/z5puco39hrv9k42ggdvxnss1rtef4j3l) and specify the correct path in the variable `cpm_param_path` in the code cell below. These parameters are stored in a pre-saved file named `cpm_params.pkl`, which contains the configuration for each WIMUSim component.\n",
    "\n",
    "### **Understanding the Loaded Parameters**\n",
    "The loaded `cpm_params` dictionary contains the following entries:\n",
    "\n",
    "- **`B_list`**: A list of Body parameters for each subject, specifying limb lengths and joint constraints.\n",
    "- **`D_list`**: A list of Dynamics parameters, which define joint orientations and translations over time.\n",
    "- **`P_list`**: A list of Placement configurations for the IMUs relative to each body segment.\n",
    "- **`H_list`**: A list of Hardware characteristics for each IMU, including sensor-specific biases and noise.\n",
    "- **`target_list`**: Reference IMU signals for each subject, serving as the ground truth for evaluation.\n",
    "\n",
    "Each of these lists corresponds to the REALDISP subjects 1 to 10 and will be used to initialize the `CPM` object for generating new virtual IMU data."
   ],
   "id": "86cd7ef0d33c3156"
  },
  {
   "cell_type": "code",
   "id": "8008d5d38a1be5eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:04:31.810003Z",
     "start_time": "2024-10-05T15:04:30.703862Z"
    }
   },
   "source": [
    "# Step 1: Specify the path to the pre-saved CPM parameters\n",
    "# Before running this cell, download the parameters file from the given link and set the correct path.\n",
    "cpm_param_path = f\"<path-to-the-pkl-file>/cpm_params.pkl\"\n",
    "\n",
    "# Step 2: Load the CPM parameters from the specified path\n",
    "# The loaded file contains parameters for subjects 1 to 10 in the REALDISP ideal scenario.\n",
    "# P and H are configured for two sensor placements: Right Lower Arm (RLA) and Left Lower Arm (LLA).\n",
    "with open(cpm_param_path, \"rb\") as f:\n",
    "    cpm_params = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **2. Define the Comprehensive Parameter Mixing (CPM) Object**\n",
    "\n",
    "The next step is to create the **Comprehensive Parameter Mixing (CPM)** object using the parameters we loaded in the previous step. The **CPM** object is a core component in WIMUSim that allows us to generate new combinations of **Body (B)**, **Dynamics (D)**, **Placement (P)**, and **Hardware (H)** parameters. By mixing these parameter sets, we can simulate diverse subject configurations and sensor setups, creating a rich and varied synthetic IMU dataset.\n",
    "\n",
    "### **What is Comprehensive Parameter Mixing (CPM)?**\n",
    "CPM is a systematic way to combine different parameter sets, generating a large number of virtual IMU data samples by altering the following aspects:\n",
    "1. **Body (B)**: Variations in body morphology (e.g., different limb lengths, body segments).\n",
    "2. **Dynamics (D)**: Variations in joint movements and temporal sequences.\n",
    "3. **Placement (P)**: Changes in the relative positions and orientations of the IMUs.\n",
    "4. **Hardware (H)**: Variations in sensor-specific noise, biases, and sampling rates.\n",
    "\n",
    "### **Creating the CPM Object**\n",
    "To create the `CPM` object, we pass the parameter lists (`B_list`, `D_list`, `P_list`, and `H_list`) for the REALDISP subjects 1 to 10. Additionally, we specify the `target_list`, which contains the reference IMU data for each subject. The `window` and `stride` parameters are used to define how the data is segmented for model training:\n",
    "\n",
    "- **`window`**: Specifies the length of the sliding window used to segment the time-series IMU data.\n",
    "- **`stride`**: Defines the step size between consecutive windows."
   ],
   "id": "7b2e005400bdfe12"
  },
  {
   "cell_type": "code",
   "id": "fc69737b6d2dcc0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:04:31.817600Z",
     "start_time": "2024-10-05T15:04:31.812025Z"
    }
   },
   "source": [
    "realdisp_cpm_dataset = CPM(\n",
    "        B_list=cpm_params[\"B_list\"],\n",
    "        D_list=cpm_params[\"D_list\"],\n",
    "        P_list=cpm_params[\"P_list\"],\n",
    "        H_list=cpm_params[\"H_list\"],\n",
    "        target_list=cpm_params[\"target_list\"],\n",
    "        window=100, \n",
    "        stride=25,\n",
    "        acc_only=False,\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Use GPU.\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **3. Generate Data with CPM**\n",
    "\n",
    "Now that we have defined the **Comprehensive Parameter Mixing (CPM)** object, we can proceed to generate a diverse set of virtual IMU data using various combinations of the **Body (B)**, **Dynamics (D)**, **Placement (P)**, and **Hardware (H)** parameters.\n",
    "\n",
    "### **Generating Virtual IMU Data**\n",
    "The `generate_data()` method of the `CPM` object randomly choose `n_combinations` from the given parameter lists to create new virtual IMU data samples. Each sample represents a unique configuration, reflecting realistic variations in the human body model, body movement dynamics, sensor placements, and sensor characteristics.\n",
    "\n",
    "- **`n_combinations`**: This parameter specifies the number of parameter combinations to generate. For example, setting `n_combinations=100` will produce 100 different virtual IMU samples by varying the B, D, P, and H parameters across subjects.\n",
    "\n",
    "> **Note**: The generated data is stored in the `realdisp_cpm_dataset.data` attribute, and the corresponding labels are stored in `realdisp_cpm_dataset.target`."
   ],
   "id": "611a66f06255fdb2"
  },
  {
   "cell_type": "code",
   "id": "675f787f697204e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:04:32.556072Z",
     "start_time": "2024-10-05T15:04:31.819611Z"
    }
   },
   "source": [
    "# This will set the realdisp_cpm_dataset.data and realdisp_cpm_dataset.target attributes\n",
    "realdisp_cpm_dataset.generate_data(\n",
    "        n_combinations=10  # Just for initialization. Can be any number.\n",
    "    )\n",
    "\n",
    "print(f\"Generated {realdisp_cpm_dataset.__len__()} windows of virtual IMU data.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating virtual IMU data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 55861 windows of virtual IMU data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Using the Generated Data with PyTorch’s DataLoader**\n",
    "The generated dataset can be used with PyTorch’s `DataLoader` to efficiently batch and shuffle the data for training machine learning models. This allows us to seamlessly integrate WIMUSim’s synthetic IMU data into model training pipelines.\n",
    "\n",
    "\n",
    "### **Understanding the Output Data**\n",
    "- **`data`**: Contains the generated virtual IMU signals. For each sample, the data is represented as a 3D tensor of shape `[batch_size, window_size, num_features]`.\n",
    "  - `batch_size`: The number of samples in each batch (e.g., 1024).\n",
    "  - `window_size`: The length of each time-series window (e.g., 100).\n",
    "  - `num_features`: The number of features for each IMU signal (e.g., 12 for 6-axis IMU data with acceleration and gyroscope signals).\n",
    "  \n",
    "- **`target`**: Corresponding label for each sample (e.g., activity type or subject ID).\n",
    "- **`idx`**: Unique identifier for each data sample, useful for tracking and debugging.\n"
   ],
   "id": "dcae1a3357ac1f09"
  },
  {
   "cell_type": "code",
   "id": "17731bf72adbcb70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:04:32.574766Z",
     "start_time": "2024-10-05T15:04:32.558193Z"
    }
   },
   "source": [
    "# You can use this with torch.dataloader\n",
    "data_loader = DataLoader(\n",
    "    realdisp_cpm_dataset,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "# Print the shape of the first batch\n",
    "for data, target, idx in data_loader:\n",
    "    print(f\"Data shape: {data.shape}\")\n",
    "    print(f\"Target shape: {target.shape}\")\n",
    "    print(f\"Index shape: {idx.shape}\")\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([1024, 100, 12])\n",
      "Target shape: torch.Size([1024])\n",
      "Index shape: torch.Size([1024])\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **4. Personalized Dataset Generation (PDG)**\n",
    "\n",
    "In the previous section, we generated a diverse set of virtual IMU data using multiple parameter combinations for subjects 1 to 10. While this approach captures a wide range of subject-specific variations, it treats all subjects as separate entities and combines their parameters freely. However, in some cases, we may want to focus on generating personalized datasets for a specific subject, where we retain most of the subject's unique characteristics and only introduce controlled variations around a limited set of parameters.\n",
    "\n",
    "### **What is Personalized Dataset Generation (PDG)?**\n",
    "**Personalized Dataset Generation (PDG)** involves fixing certain parameters (e.g., body morphology or sensor placement) for a target subject while varying others to introduce realistic intra-subject variability. This approach is useful for creating subject-specific data that captures plausible variations for a particular individual.\n",
    "\n",
    "\n",
    "### **Creating a PDG Object**\n",
    "To demonstrate PDG, we will limit the **Body (B)**, **Placement (P)**, and **Hardware (H)** parameters to a specific subject (e.g., Subject 3) and vary the **Dynamics (D)** parameter to simulate different movement patterns for this subject. This configuration will produce a dataset that is tailored to the unique characteristics of Subject 3, making it ideal for personalized training and evaluation.\n",
    "\n",
    "### **Use Case: Personalized HAR Model Training**\n",
    "Personalized datasets like these are particularly valuable when training **personalized HAR models**. Such models can achieve better performance for specific users by leveraging subject-specific data that captures realistic intra-subject variability. This approach can also be used to fine-tune general HAR models for specific subjects, improving their robustness to individual variations."
   ],
   "id": "4e5c4e49614051de"
  },
  {
   "cell_type": "markdown",
   "id": "be69346419081b97",
   "metadata": {},
   "source": [
    "By limiting some of the parameters to specific subject, you can do Personalized Dataset Generation too.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "695d55fa84cb3eae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:04:32.582624Z",
     "start_time": "2024-10-05T15:04:32.575860Z"
    }
   },
   "source": [
    "realdisp_pdg_dataset = CPM(\n",
    "        B_list=cpm_params[\"B_list\"][3:4],\n",
    "        D_list=cpm_params[\"D_list\"],\n",
    "        P_list=cpm_params[\"P_list\"][3:4],\n",
    "        H_list=cpm_params[\"H_list\"][3:4],\n",
    "        target_list=cpm_params[\"target_list\"],\n",
    "        window=100, \n",
    "        stride=25,\n",
    "        acc_only=False,\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Use GPU.\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Generating Personalized Data**\n",
    "We can now use the `generate_data()` method again to generate virtual IMU data for this subject. Since the B, P, and H parameters are fixed, only the D parameters will vary, simulating different movement patterns for Subject 3:"
   ],
   "id": "f78139d3b543fc24"
  },
  {
   "cell_type": "code",
   "id": "aa8a2ee334d81293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T15:04:32.851399Z",
     "start_time": "2024-10-05T15:04:32.583839Z"
    }
   },
   "source": [
    "# Generate personalized data for Subject 3\n",
    "realdisp_pdg_dataset.generate_data(n_combinations=5)  # Generate 5 unique movement patterns\n",
    "\n",
    "print(f\"Generated {realdisp_pdg_dataset.__len__()} virtual IMU samples for Subject 3.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating virtual IMU data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 29243 virtual IMU samples for Subject 3.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Conclusion**\n",
    "\n",
    "In this notebook, we explored how to use WIMUSim's **parameter transformation capabilities** to generate diverse and realistic virtual IMU datasets for Human Activity Recognition (HAR) models. "
   ],
   "id": "ef56262736a5e080"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
